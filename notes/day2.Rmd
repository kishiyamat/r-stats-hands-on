---
title: "Day2"
output: ioslides_presentation
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(readr)
library(dplyr)
library(lme4)
library(lmerTest)
```

# 『Rで学ぶ統計学入門』勉強会

## 全体のアウトライン

Day1

-   t検定
-   補足: t検定と線形モデル
-   ANOVA

**Day2**

-   LMEとランダム構造
-   複数のランダム効果と実例
-   モデル選択
-   (LMEの拡張)

## 前回の復習

-   t検定
    -   帰無仮説を立てた検定
    -   概要: 差がないときに0となる値tを計算、仮説の棄却・採用
-   補足: t検定と線形モデル
    -   データフレーム
    -   フォーミュラ
    -   モデル
-   ANOVA
    -   多重比較
    -   交互作用

## t検定の復習

-   帰無仮説を立てた検定
-   概要: 差がないときに0となる値tを計算、仮説の棄却・採用

```{r}
data_b <- data.frame(
  m = c(142.3, 142.5, 145.7, 143.5, 144.2, 145.1, 145.9, 145.2, 146.8, 145.7, 145.4, 144.6, 144.2, 145.9, 142.1),
  f = c(143.5, 144.6, 143.4, 146.6, 145.3, 147.7, 147.2, 147.8, 145.3, 145.7, 147.5, 147.2, 148.8, 147.9, 143.3)
)
t.test(data_b$m, data_b$f, var = T)
```

このtは独立変数(要因)の変化に伴う従属変数の変化を、
ばらつきで割ったものでした。
本当の平均値$\mu$が同じであると仮定した場合、
手元のデータの平均も同じなら0になるような値です。
もし同じでないなら、0からはずれていきます。
そして事前に決めた$\alpha$に従って帰無仮説（元の仮定）を棄却します。

$$
t=\frac{(\bar{X_m}-\bar{X_f})-(\mu_m-\mu_f)}{s_{\bar{X_m}-\bar{X_f}}}
$$

このt検定は「線形モデル」という見方もできました。

## 補足: t検定と線形モデル

-   データフレーム: `data_c`
-   フォーミュラ: `height ~ sex`
-   モデル: `lm`

```{r}
# データフレーム
data_c <- data.frame(
  sex = c(rep(1, 15), rep(0, 15)),
  height = c(data_b$m, data_b$f)
)
# 図示
ggplot(data_c, aes(x = as.factor(sex), y = height)) +
  geom_boxplot()
```

上の図を見ると、x軸のfactorが0→1になると、
平均値の分だけマイナスになることがわかります。
そうなると、もともとの式は y = -1.51\*性別 + 146.1 のように表せます。
これを線形モデルでは「フォーミュラ」を使って表現します。
従属変数`~`独立変数のように表現します。

```{r}
# モデルはsummaryでp値なども確認できる。
summary(lm(height ~ sex, data = data_c))
# 傾き(効果、差)とばらつきとtの関係は今後も出てきます。
```

この「線形モデル」の枠組みを広げて、ランダム構造を考えていきます。

-   ランダム構造(被験者の効果やアイテムの効果)
-   連続値の独立変数など

## LMEとランダム構造

ランダム構造を考えるにあたって、 まずはサンプルデータを見てみましょう。
夜ふかし何日目かがx、反応時間がyに入っているデータです。
先程は右肩下がりでしたが、今回は右肩あがりなデータになっています。

```{r}
ggplot(sleepstudy, aes(x = as.factor(Days), y = Reaction)) +
  geom_boxplot()
```

今回のデータも傾き(効果、差)とばらつき、tの関係がなりたちます。
傾きとして、Xが5増えるとYは50増えているので、傾きは10くらいになりそうです。
Xが0の時のYが切片になるので、切片は250くらいです。 そうすると、 y =
10\*x + 250 という式が作れそうです。

Rの `f = Reaction ~ Days` という式は `f = Reaction ~ Days + 1`
の略です。これを `lm`に与えると、Daysと1にかけてReactionとなるような値を
推定してくれます。

```{r}
f <- Reaction ~ Days
m <- lm(f, sleepstudy)
summary(m)
```

ですので、厳密には $y = 10.467*x + 251.405$ という式が作れそうです。
ただ実はこのデータ、複数の被験者がいます。
人により、寝不足の影響がない人(335)や、
順当に反応時間が遅くなる人(308)もいそうです。傾きが違えば、線を引いた時の切片も違いそうです。

```{r}
ggplot(sleepstudy, aes(x = as.factor(Days), y = Reaction)) +
  facet_wrap(. ~ Subject) +
  geom_boxplot()
```

こうした個人差を考えないで直線を引くだけでは、
過剰に反応する被験者がいた時や全く逆の反応をする被験者に
引っ張られてしまいます。
ですので、こうした「ランダムな傾き・切片」と興味のある「固定効果」を
混ぜて線形モデルを作ってあげます。
この混ぜたモデルのことを「線形混合モデル」と呼びます。

具体的な式を見てみると、もともとは $y = 10.467*x + 251.405*1$ でしたが、
ここに「ランダムな傾き・切片」を混ぜてみます。そうすると、

$$
y = (10.467+被験者308のランダム効果)*\rm{Days} + (251.405+被験者308のランダム切片)*1
$$ となります。さきほど、以下のような話をしました。

> Rの `f = Reaction ~ Days` という式は `f = Reaction ~ Days + 1`
> の略です。これを
> `lm`に与えると、Daysと1にかけてReactionとなるような値を
> 推定してくれます。

つまり、`Reaction ~ Days` を与えると全体の傾きと切片をもとめてくれます。

ここで次に `Reaction ~ Days+1 + (Days+1|Subject)`
という式を考えてみます。 これを `lmer` に与えると、
被験者ごとの傾きと切片`(Days+1|Subject)`を考慮して
全体の傾きと切片を求めてくれます。 全体の傾きと切片は `summary`
で確認できます。

```{r}
f_lmer <- Reaction ~ Days + 1 + (Days + 1 | Subject)
m <- lmer(f_lmer, sleepstudy)
summary(m)
```

被験者ごとのランダム効果（傾き、切片）は`ranef`で確認できます。
さきほど、

> 人により、寝不足の影響がない人(335)や、
> 順当に反応時間が遅くなる人(308)もいそうです。傾きが違えば、線を引いた時の切片も違いそうです。

といいましたが308は+になっているので、うまく反映されていそうです。

```{r}
head(ranef(m)$Subject)
# 308	  2.258551	 9.198976
# 309	-40.398738	-8.619681
```

固定効果は以下のように求まっており、

``` r
Fixed effects:
            Estimate Std. Error      df t value Pr(>|t|)    
(Intercept)  251.405      6.825  17.000  36.838  < 2e-16 ***
Days          10.467      1.546  17.000   6.771 3.26e-06 ***
```

被験者番号308のInterceptは約2.26、Daysの効果は約9.20であることを踏まえると、以下のようにReactionを求められます（記号の
$\sim$ は「誤差を伴って従う」という意味です）。

$$
\rm{Reaction}\sim 10.467*\rm{Days} + 251.405*1 + (9.1989758*\rm{Days} + 2.2585509 *1)
$$

さらに式を変えると以下のように書き換えられます。

$$
\rm{Reaction}\sim (10.467+9.1989758)*\rm{Days} + (251.405 + 2.2585509)*1
$$

このカッコには固定効果とランダム効果が混在しています。
これが線形混合モデルの混合の意味になります。
これでランダム効果を考慮しつつ、傾き、ばらつき、t値、p値を求めてくれます。

```{r}
summary(m)
```

実際に実験をする際は複数のアイテム、複数の被験者に対して行う。

-   一つのアイデムでは「そのアイテムだったからでは？」と突っ込めてしまう
-   一つの被験者では「その被験者だったからでは？」と突っ込めてしまう

lmer を使うと、上記のようにランダム構造を仮定でき、
しかも同時に複数のランダム要因を考慮できます。
実際の実験を見ながら、被験者とアイテムのランダム要因のモデルを試してみましょう。

## 複数のランダム効果と実例

具体例とともに見ていきましょう。紹介する研究の対象は
「主要部前処理における文頭名詞句の長さの役割」です（広瀬ゼミの曽根さんが提供してくださいました。）。
まずHirose(2003)では、潜在的な韻律境界の位置が統語構造の再分析の段階で、
節境界の位置を示す情報として解釈される可能性を示しています。

以下の文は両方、 **友人たちに** で再分析が起きますが、// の位置に
韻律境界が置かれ、そこに節境界も奥とすると「処方箋を」でaは困ることになります。

a.  森下が 新薬を // 心から 信用した **友人達に** 処方箋を 送った。
b.  細川と森下が // 新薬を 心から 信用した **友人達に** 処方箋を
    送った。

再分析ではなく、初分析ではどうでしょうか。
例えば、下の長い名詞句を置いたとき(Long条件)、
以下の//の位置に韻律境界が置かれるとします。
もし韻律境界//と同じ位置に節境界を置くなら、「破った」で困りません。
これに対し、Short条件で//で節境界を置いてしまうと、「破った」で困ることになります。

-   Long\
    定年間近の教授が//学生に 図書館司書が 見せた 珍しい 古文書を
    破った。
-   Short\
    教授が 学生に // 図書館司書が 見せた 珍しい 古文書を 破った。

理由としては、Short条件の//で節境界を置いてしまうと、
「...に破った」という変な形になるからです。
したがって、「破った」という動詞は「学生に」が主節より下の節である
関係節にくっつかなければなりません(Low attachment, LA)。
対して、「見せた」という動詞は「...に見せた」と言えるので、
「学生に」は主節にくっつけます（High attachment, HA）。 その場合、
//で節境界を置いても「見せた」では困りません。

-   LA, Short\
    教授が 学生に // 図書館司書が 見せた 珍しい 古文書を 破った。
-   HA, Short\
    教授が 学生に // 図書館司書が 見せた 珍しい 古文書を 見せた。

したがって、第７領域での読み時間は LA\>HAだと予想できます。
これに対し、Long条件では韻律境界と共に「学生に」を関係節内に入れるなら、
最初からLow Attachment なので第７領域で読み時間は増えません。
HAの「見せた」に対しても、主節は「教授が古文書を見せた」なので読み時間は増えません。
ですので、Short条件で見られたような差はLong条件では見られないことになります。

-   LA, Long\
    定年間近の教授が//学生に 図書館司書が 見せた 珍しい 古文書を
    破った。
-   HA, Long\
    定年間近の教授が//学生に 図書館司書が 見せた 珍しい 古文書を
    見せた。

ここまで出てきた要因と水準をa--dでまとめると、以下のようになります。
cはaやb,dより読み時間が増えます。aとb,dの間では読み時間の差を積極的に
予測しません。
これはShort:LAの交互作用を狙う、典型的なパターンになります。

a.  HA, Short\
    教授が_学生に\_//図書館司書が_破った_珍しい_古文書を_見せた。
b.  HA, Long\
    定年間近の教授が\_//学生に_図書館司書が_破った_珍しい_古文書を_見せた。
c.  LA, Short\
    教授が 学生に // 図書館司書が 見せた 珍しい 古文書を 破った。
d.  LA, Long\
    定年間近の教授が // 学生に 図書館司書が 見せた 珍しい 古文書を
    破った。

```{r}
d_sone <- data.frame(
  Attachment = c("HA", "HA", "LA", "LA"),
  Noun = c("Short", "Long", "Short", "Long"),
  RT = c(200, 200, 400, 200)
)
ggplot(d_sone, aes(x = Noun, y = RT, color = Attachment)) +
  geom_boxplot()
```

先程、以下のように説明しました。したがって、
今回のデータも複数の被験者に対して、複数のアイテムを使っています。

> 実際に実験をする際は複数のアイテム、複数の被験者に対して行う。
>
> -   一つのアイデムでは「そのアイテムだったからでは？」と突っ込めてしまう
> -   一つの被験者では「その被験者だったからでは？」と突っ込めてしまう

一旦、データを見てみましょう。
データ事前に配布したファイルをread_csvで読み込みましょう。
なお、encodeの話などは
<https://oku.edu.mie-u.ac.jp/~okumura/stat/readr.html>
が詳しいので、ご自身のデータで問題が起きたときはこちらをご参考ください。

```{r}
# データの読み込み
regs <- read_csv(file = "../data/PL_LME.csv", locale = locale(encoding = "CP932"))
head(regs)
```

データを見てみると、atが　highなものは「...に」を取れる動詞だとわかります。
lenがlongなものは、「定年間近の教授が」のような長い名詞句でした。
モデリングの前に、要因を数字としてあげます。

```{r}
# エンコーディング
regs$nlen <- ifelse(regs$len == "short", 1, 2) #subject length (short vs. long)
regs$nat <- ifelse(regs$at == "high", 1, 2)  # attachment type (high vs.low)
regs$clen <- scale(regs$nlen)	# Scale(convergeしやすくなる)
regs$cat <-  scale(regs$nat) # Scale -1, 1
head(regs)
```

```{r}
ggplot(regs, aes(x = len, y = rt, color = at)) +
  geom_boxplot()
```

## モデル選択

これを先程のlmerを使ってモデリングしてみましょう。 ランダム効果の部分は
`+(1+clen*cat|subj) + (1+clen*cat|item)`となっている
ことからわかるように、ランダム切片（被験者ごと、アイテムごとにどれくらい遅いか）
だけでなく、ランダム傾きも入っています(`clen*cat`)。

```{r}
rt.lme10 <- lmer(rt ~ clen*cat + (1+clen*cat|subj) + (1+clen*cat|item), data=regs)
summary(rt.lme10)
```

ただ、同程度の良いモデルならよりシンプルなモデルのほうが良い、
という原則に基づいて、ここからランダム構造を削っていきます。
(複雑なモデルを作って削っていく方法を backward elimination といいます)

以下ではVarianceの小さいものから削っていきます。
subjの(Intercept)を見るとVarianceが大きな値になっています。
これは、被験者ごとのベースとなる読み時間の差が大きいということです。
ランダム効果の目的はこうしたばらつきの大きな差を固定効果から抜くことなので、
こうしたVarianceの大きな効果は残しておきます。
逆に、Varianceの小さなものはあってもなくても同じかもしれないので、
試しに削っていく...ということを繰り返していきます。

```{r}
# varianceの１番小さい要因をランダム効果から抜いていく
rt.lme9 <- lmer(rt ~ clen*cat + (1+clen*cat|subj) + (1+clen+cat|item), data=regs)
anova(rt.lme10, rt.lme9)
```

上では、itemの`clen*cat`が最も小さいVarianceなので、削って差をみてみます。
その結果、差はないようなのでまた削っていきます。 ここでの `anova` 関数は
`?anova` をするとマニュアルが出てきますが、
より複雑なモデルとの間でデータとのフィットの良さを比較してくれます。
(詳しくは
<https://bookdown.org/ndphillips/YaRrr/comparing-regression-models-with-anova.html>
を参照)

Varianceの小さいランダム構造を落としていってモデルを作成し、
anovaに与えてみます。

```{r}
# 省きますが、Varianceの小さいものから削っています。
rt.lme8 <- lmer(rt ~ clen*cat + (1+clen+cat|subj) + (1+clen+cat|item), data=regs)
rt.lme7 <- lmer(rt ~ clen*cat + (1+clen+cat|subj) + (1+clen|item), data=regs)
rt.lme6 <- lmer(rt ~ clen*cat + (1+clen|subj) + (1+clen|item), data=regs)  # Singularではいのはこれ
rt.lme5 <- lmer(rt ~ clen*cat + (1+clen|subj) + (1|item), data=regs)
rt.lme0 <- lmer(rt ~ clen*cat + (1|subj) + (1|item), data=regs)
anova(rt.lme10, rt.lme9, rt.lme8, rt.lme7, rt.lme6, rt.lme5, rt.lme0)
```

この結果の見方としては、6→7や8→9と複雑にしたときにフィットがよくなり、
あるいは9→8、7→6と削った時にフィットが悪くなる、という結果に解釈できます。
今回は backwardなので、9を採用します。

```{r}
summary(rt.lme9)
```

## 今回扱わなかった範囲

-   エンコーディング: モデリングの前に、要因を数字としてあげます。
    -   <https://phiz.c.u-tokyo.ac.jp/~hiroselab/stats/0907.html>
    -   峰見さんの資料
-   GLMの理論:
    今回は従属変数は連続地でしたが、少しひねるとカテゴリカルな値も利用できます。
    -   <https://kishiyamat.github.io/tutorial-lme-vwp/>
    -   lmeと言いつつglmerを使っている岸山の資料

## まとめ

-   構造的なノイズとはなにか
-   `lmer`による構造的なノイズのモデリング
-   複雑すぎるモデルの改善
